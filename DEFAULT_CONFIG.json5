/// This file attempts to list and document available configuration elements.
/// For a more complete view of the configuration's structure, check out `zenoh/src/config.rs`'s `Config` structure.
/// Note that the values here are correctly typed, but may not be sensible, so copying this file to change only the parts that matter to you is not good practice.
{
  /// The identifier (as hex-string) that zenohd must use.
  /// If not set, a random UUIDv4 will be used.
  /// WARNING: this id must be unique in your zenoh network.
  // id: "5975702c206974277320415343494921",

  /// The node's mode (router, peer or client)
  mode: "peer",

  /// Which endpoints to connect to. E.g. tcp/localhost:7447.
  /// By configuring the endpoints, it is possible to tell zenoh which router/peer to connect to at startup.
  connect: {
    endpoints: [
      // "<proto>/<address>"
    ],
  },

  /// Which endpoints to listen on. E.g. tcp/localhost:7447.
  /// By configuring the endpoints, it is possible to tell zenoh which are the endpoints that other routers,
  /// peers, or client can use to establish a zenoh session.
  listen: {
    endpoints: [
      // "<proto>/<address>"
    ],
  },
  /// Configure the scouting mechanisms and their behaviours
  scouting: {
    /// In client mode, the period dedicated to scouting for a router before failing
    timeout: 3000,
    /// In peer mode, the period dedicated to scouting remote peers before attempting other operations
    delay: 200,
    /// The multicast scouting configuration.
    multicast: {
      /// Whether multicast scouting is enabled or not
      enabled: true,
      /// The socket which should be used for multicast scouting
      address: "224.0.0.224:7446",
      /// The network interface which should be used for multicast scouting
      interface: "auto", // If not set or set to "auto" the interface if picked automatically
      /// Which type of Zenoh instances to automatically establish sessions with upon discovery on UDP multicast.
      /// Accepts a single value or different values for router, peer and client.
      /// Each value is bit-or-like combinations of "peer", "router" and "client".
      autoconnect: { router: "", peer: "router|peer" },
      /// Whether or not to listen for scout messages on UDP multicast and reply to them.
      listen: true,
    },
    /// The gossip scouting configuration.
    gossip: {
      /// Whether gossip scouting is enabled or not
      enabled: true,
      /// Which type of Zenoh instances to automatically establish sessions with upon discovery on gossip.
      /// Accepts a single value or different values for router, peer and client.
      /// Each value is bit-or-like combinations of "peer", "router" and "client".
      autoconnect: { router: "", peer: "router|peer" },
    },
  },

  /// Configuration of data messages timestamps management.
  timestamping: {
    /// Whether data messages should be timestamped if not already.
    /// Accepts a single boolean value or different values for router, peer and client.
    enabled: { router: true, peer: false, client: false },
    /// Whether data messages with timestamps in the future should be dropped or not.
    /// If set to false (default), messages with timestamps in the future are retimestamped.
    /// Timestamps are ignored if timestamping is disabled.
    drop_future_timestamp: false,
  },

  /// The routing strategy to use and it's configuration.
  routing: {
      /// The routing strategy to use in peers and it's configuration.
      peer: {
          /// The routing strategy to use in peers. ("peer_to_peer" or "linkstate").
          mode: "peer_to_peer",
      },
  },

//  /// The declarations aggregation strategy.
//  aggregation: {
//      /// A list of key-expressions for which all included subscribers will be aggregated into.
//      subscribers: [
//        // key_expression
//      ],
//      /// A list of key-expressions for which all included publishers will be aggregated into.
//      publishers: [
//        // key_expression
//      ],
//  },

  /// Configure internal transport parameters
  transport: {
    unicast: {
      /// Timeout in milliseconds when opening a link
      accept_timeout: 10000,
      /// Maximum number of zenoh session in pending state while accepting
      accept_pending: 100,
      /// Maximum number of sessions that can be simultaneously alive
      max_sessions: 1000,
      /// Maximum number of incoming links that are admitted per session
      max_links: 1,
    },
    qos: {
      enabled: true,
    },
    link: {
      /// Configure the zenoh TX parameters of a link
      tx: {
        /// The largest value allowed for Zenoh message sequence numbers (wrappring to 0 when reached).
        /// When establishing a session with another Zenoh instance, the lowest value of the two instances will be used.
        /// Defaults to 2^28.
        sequence_number_resolution: 268435456,
        /// Link lease duration in milliseconds to announce to other zenoh nodes
        lease: 10000,
        /// Number of keep-alive messages in a link lease duration. If no data is sent, keep alive
        /// messages will be sent at the configured time interval.
        /// NOTE: In order to consider eventual packet loss and transmission latency and jitter,
        ///       set the actual keep_alive timeout to one fourth of the lease time.
        ///       This is in-line with the ITU-T G.8013/Y.1731 specification on continous connectivity
        ///       check which considers a link as failed when no messages are received in 3.5 times the
        ///       target interval.
        keep_alive: 4,
        /// Batch size in bytes is expressed as a 16bit unsigned integer.
        /// Therefore, the maximum batch size is 2^16-1 (i.e. 65535).
        /// The default batch size value is the maximum batch size: 65535.
        batch_size: 65535,
        /// Each zenoh link has a transmission queue that can be configured
        queue: {
          /// The size of each priority queue indicates the number of batches a given queue can contain.
          /// The amount of memory being allocated for each queue is then SIZE_XXX * BATCH_SIZE.
          /// In the case of the transport link MTU being smaller than the ZN_BATCH_SIZE,
          /// then amount of memory being allocated for each queue is SIZE_XXX * LINK_MTU.
          /// If qos is false, then only the DATA priority will be allocated.
          size: {
            control: 1,
            real_time: 1,
            interactive_high: 1,
            interactive_low: 1,
            data_high: 2,
            data: 4,
            data_low: 4,
            background: 4,
          },
          /// The initial exponential backoff time in nanoseconds to allow the batching to eventually progress.
          /// Higher values lead to a more aggressive batching but it will introduce additional latency.
          backoff: 100,
        },
      },
      /// Configure the zenoh RX parameters of a link
      rx: {
        /// Receiving buffer size in bytes for each link
        /// The default the rx_buffer_size value is the same as the default batch size: 65335.
        /// For very high throughput scenarios, the rx_buffer_size can be increased to accomodate
        /// more in-flight data. This is particularly relevant when dealing with large messages.
        /// E.g. for 16MiB rx_buffer_size set the value to: 16777216.
        buffer_size: 65535,
        /// Maximum size of the defragmentation buffer at receiver end.
        /// Fragmented messages that are larger than the configured size will be dropped.
        /// The default value is 1GiB. This would work in most scenarios.
        /// NOTE: reduce the value if you are operating on a memory constrained device.
        max_message_size: 1073741824,
      },
      /// Configure TLS specific parameters
      tls: {
        root_ca_certificate: null,
        server_private_key: null,
        server_certificate: null,
        client_auth: null,
        client_private_key: null,
        client_certificate: null,
      },
    },
    /// Shared memory configuration
    shared_memory: {
      enabled: true,
    },
    /// Access control configuration
    auth: {
      /// The configuration of authentification.
      /// A password implies a username is required.
      usrpwd: {
        user: null,
        password: null,
        /// The path to a file containing the user password dictionary
        dictionary_file: null,
      },
      pubkey: {
        public_key_pem: null,
        private_key_pem: null,
        public_key_file: null,
        private_key_file: null,
        key_size: null,
        known_keys_file: null,
      },
    },
  },

  /// Configure the Admin Space
  /// Unstable: this configuration part works as advertised, but may change in a future release
  adminspace: {
    // read and/or write permissions on the admin space
    permissions: {
      read: true,
      write: false,
    },
  },

  ///
  /// Plugins configurations
  ///
//  /// Directories where plugins configured by name should be looked for. PLugins configured by __path__ are not subject to lookup
//  plugins_search_dirs: [],
//  /// Plugins are only loaded if present in the configuration. When starting
//  /// Once loaded, they may react to changes in the configuration made through the zenoh instance's adminspace.
//  plugins: {
//    /// If no `__path__` is given to a plugin, zenohd will automatically search for a shared library matching the plugin's name (here, `libzplugin_rest.so` would be searched for on linux)
//
//    /// Configure the REST API plugin
//    rest: {
//      /// Setting this option to true allows zenohd to panic should it detect issues with this plugin. Setting it to false politely asks the plugin not to panic.
//      __required__: true, // defaults to false
//      http_port: 8000,
//    },
//
//    /// Configure the storage manager plugin
//    storage_manager: {
//      /// When a path is present, automatic search is disabled, and zenohd will instead select the first path which manages to load.
//      __path__: [
//        "./target/release/libzplugin_storage_manager.so",
//        "./target/release/libzplugin_storage_manager.dylib",
//      ],
//      /// The "memory" volume is always available, but you may create other volumes here, with various backends to support the actual storing.
//      volumes: {
//        /// An influxdb backend is also available at https://github.com/eclipse-zenoh/zenoh-backend-influxdb
//        influxdb: {
//          url: "https://myinfluxdb.example",
//          /// Some plugins may need passwords in their configuration.
//          /// To avoid leaking them through the adminspace, they may be masked behind a privacy barrier.
//          /// any value held at the key "private" will not be shown in the adminspace.
//          private: {
//            username: "user1",
//            password: "pw1",
//          },
//        },
//        influxdb2: {
//          /// A second backend of the same type can be spawned using `__path__`, for examples when different DBs are needed.
//          backend: "influxdb",
//          private: {
//            username: "user2",
//            password: "pw2",
//          },
//          url: "https://localhost:8086",
//        },
//      },
//
//      /// Configure the storages supported by the volumes
//      storages: {
//        demo: {
//          /// Storages always need to know what set of keys they must work with. These sets are defined by a key expression.
//          key_expr: "demo/memory/**",
//          /// Storages also need to know which volume will be used to actually store their key-value pairs.
//          /// The "memory" volume is always available, and doesn't require any per-storage options, so requesting "memory" by string is always sufficient.
//          volume: "memory",
//        },
//        demo2: {
//          key_expr: "demo/memory2/**",
//          volume: "memory",
//          /// If multiple storages subscribing to the same key_expr should be synchronized, declare them as replicas.
//          /// In the absence of this configuration, a normal storage is initialized
//          /// Note: all the samples to be stored in replicas should be timestamped
//          replica_config: {
//            /// Specifying the parameters is optional, by default the values provided will be used.
//            /// Time interval between different synchronization attempts in seconds
//            publication_interval: 5,
//            /// Expected propagation delay of the network in milliseconds
//            propagation_delay: 200,
//            /// This is the chunk that you would like your data to be divide into in time, in milliseconds.
//            /// Higher the frequency of updates, lower the delta should be chosen
//            /// To be efficient, delta should be the time containing no more than 100,000 samples
//            delta: 1000,
//          }
//        },
//        influx_demo: {
//          key_expr: "demo/influxdb/**",
//          /// This prefix will be stripped of the received keys when storing.
//          strip_prefix: "demo/influxdb",
//          /// influxdb-backed volumes need a bit more configuration, which is passed like-so:
//          volume: {
//            id: "influxdb",
//            db: "example",
//          },
//        },
//        influx_demo2: {
//          key_expr: "demo/influxdb2/**",
//          strip_prefix: "demo/influxdb2",
//          volume: {
//            id: "influxdb2",
//            db: "example",
//          },
//        },
//      },
//    },
//  },

}
